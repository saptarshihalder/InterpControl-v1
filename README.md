# InterpControl

Research console for mechanistic interpretability with GPT2-Medium. Train probes, visualize activations, and steer model behavior.

## Features

- ğŸ¯ Train linear probes on any layer
- ğŸ“Š 3D PCA visualization of activation spaces
- ğŸšï¸ Steering vector control
- ğŸ§  Dual-process inference (System 1/System 2)
- ğŸ” Real-time confidence monitoring

## Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/interpcontrol.git
cd interpcontrol
```

2. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## Usage

1. Start the server:
```bash
python app.py
```

2. Open your browser to `http://localhost:8000`

3. The interface will automatically train a probe on layer 14

4. Enter prompts and experiment with:
   - Different probe layers (12-16)
   - Steering coefficients (-5 to +5)
   - System 1 vs System 2 inference

## Project Structure
```
interpcontrol/
â”œâ”€â”€ app.py              # FastAPI backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html      # React frontend
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md          # This file
```

## How It Works

1. **Probe Training**: Trains logistic regression classifiers on model activations to detect truthfulness
2. **Steering**: Applies learned direction vectors to influence model outputs
3. **Dual Processing**: Routes to System 2 (chain-of-thought) when confidence is low

## Requirements

- Python 3.8+
- 8GB+ RAM (for GPT2-Medium)
- CPU or CUDA-compatible GPU

## License

MIT
```

**.gitignore**
```
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
ENV/
env/
.venv
*.log
.DS_Store
.idea/
.vscode/
*.swp
*.swo
```

**Folder structure:**
```
interpcontrol/
â”œâ”€â”€ app.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
